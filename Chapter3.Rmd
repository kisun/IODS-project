#Logistic Regression

One way to move on from linear regression is to consider settings where the dependent (target) variable is discrete. This opens a wide range of possibilities for modelling phenomena beyond the assumptions of continuity or normality.

Logistic regression is a powerful method that is well suited for predicting and classifying data by working with probabilities. It belongs to a large family of statistical models called Generalized Linear Models (GLM). An important special case that involves a binary target (taking only the values 0 or 1) is the most typical and popular form of logistic regression. 

We will learn the concept of odds ratio (OR), which helps to understand and interpret the estimated coefficients of a logistic regression model. We also take a brief look at cross-validation, an important principle and technique for assessing the performance of a statistical model with another data set, for example by splitting the data into a training set and a testing set.

The slides and videos related to logistic regression can be found below.  
[Video: Logistic regression: probability and odds](https://player.vimeo.com/video/202056054)  
[Video: Logistic regression: Odds ratios](https://player.vimeo.com/video/202056098)  
[Video: Cross-validation: training and testing sets](https://player.vimeo.com/video/202056141)  
[Slides: Logistic regression](https://tuomonieminen.github.io/Helsinki-Open-Data-Science/#/23)

After going through the videos, we practiced [DataCamp exercises on Logistic regression](https://campus.datacamp.com/courses/helsinki-open-data-science/logistic-regression?ex=1) and started to work on the workshop (RStudio Exercise 3.

##RStudio Exercise 3

###Data Wrangling
The data for Exercise 3 was downloaded from UCI Machine Learning Repository ([link](https://archive.ics.uci.edu/ml/datasets/Student+Performance)). The zipped file contained two tables, namely student-mat.csv and student-por.csv. In this data wrangling exercise, the main task was to join two data sets and create a data frame for logistic regression analysis. More detailed information about the data is present in the next section (Data Analysis) of this exercise. The R script associated with this exercise can be found [here](https://github.com/kisun/IODS-project/blob/master/data/create_alc.R)

###Data Analysis
The joined student alcohol consumption data that was created during wrangling exercise was read into R. 
```{r}
alc<-read.table("data/alc.csv")
#head(alc)
colnames(alc)
```
The data set in this exercise is a collection of information that is associated with student's performance in two Portugese high schools. Two subjects - Mathematics (mat) and Portugese language (por) were choosen in this study. The findings from this study were published in the Proceedings of 5th FUture BUsiness TEChnology Conference (FUBUTEC 2008) during April, 2008 in Porto, Protugal([link](http://www3.dsi.uminho.pt/pcortez/student.pdf)). Altogether 33 attributes were assessed covering different aspects of student's life. More detailed attribute information can be found [here](https://archive.ics.uci.edu/ml/datasets/Student+Performance)

Here, the main goal of the analysis is to study how alcohol consumption is associated with other aspects in student's life. After going through the background information, it is a bit easier to identify interesting variables that could be related to alcohol consumption. Personally, I believe that the following are the four interesting variables that are associated with alcohol consumption:  

**Weekly study time (studytime)** : In my opinion, if a student spends more time studying, he will have less time for alcohol consumption.  

**Going out with friends (goout)** : In general, students go out with friends for parties and get-togethers. Attending such partiies and gatherings will lead higher alcohol consumption compared to those who do not participate in such activities.  

**Number of school absences (absences)** : We can think of two reasons in terms of alcohol consumption and school absences. The main reason is that when a student consumes alcohol (especially during the evening), he/she will have lesser desire to go school next day (depends on the level of consumption). Another reason might be that a student is absent from class because he has plan to drink alcholic beverages. 

**Quality of family relationships (famrel)** : I think the quality of family relationship will also affect student's attitude towards alcohol consumption and the student who has bad family relationship may consume more alcohol compare to one who has better family relationship.



In the following section, we will see in details how my hypotheses are explained by the data.
First, let's summarise the subset of the table which includes the variables I have chosen.
```{r}
library(dplyr)

my_var<- c("studytime", "absences", "goout", "famrel", "high_use")

my_var_data <- select(alc, one_of(my_var))
str(my_var_data)
```
All my chosen variables have integer values whereas information about the alcohol consumption is logical i.e True or False. Moreover, the str function also revealed the dimension of the selected data i.e 382 observations for five variables. After getting the data types, we can proceed with summarizing the table as follows:
```{r}
summary(my_var_data)

```

  
  
The summary provides basic statistics (see the table above) about each variables. If we pick a particular variable absences (i.e number of absences), we can see that some of the students are never absent (min = 0)in the class whereas there have been a student or two who was absent upto 45 days (max = 0). Overall, when we look at the summary of all variables, median vlaues reflect better than mean values to understand the natures of our hypotheses i.e more vs less (studytime and absences, goout), high vs low, good vs bad (famrel). According to that, studying more than three hours, going out more than three times a week, being absent in class more than 3 days a week and having a relationship scale of more than 4 lead the students to upper levels and vice versa.

We can have graphical representation of each of the variables as bar charts (see below).
```{r}
library(tidyr)
library(ggplot2)


gather(my_var_data) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
```

The summary tables provide information for alcohol consumption in relation to the factors for each selected variables.
```{r}
t1 <- table("Study Time" = alc$studytime, "Alcohol Usage" = alc$high_use)
round(prop.table(t1, 1)*100, 1)
t2 <- table("Going Out" = alc$goout, "Alcohol Usage" = alc$high_use)
round(prop.table(t2, 1)*100, 1)
t3 <- table("Absences" = alc$absences, "Alcohol Usage" = alc$high_use)
round(prop.table(t3, 1)*100, 1)
t4 <- table("Family Relationship" = alc$famrel, "Alcohol Usage" = alc$high_use)
round(prop.table(t4, 1)*100, 1)

```
Box plots provide more meaningful and summarized but more descriptive information for our variables as we can see the relationship of each four variables compared to alcohol consumption. Let's look into more detail how the four variables I chose are affecting alcohol consumption in high school students using box plots.

```{r, fig.width=11, fig.height=10}
library(ggpubr)
g1 <- ggplot(alc, aes(x = high_use, y = studytime, col = high_use))

p1=g1 + geom_boxplot() + xlab("Alcohol Consumption")+ ylab("Study Time") + ggtitle("Study hours and alcohol consumption")

g2 <- ggplot(alc, aes(x = high_use, y = absences, col = high_use))

p2=g2 + geom_boxplot() + xlab("Alcohol Consumption")+ ylab("Number of School Absences")  + ggtitle("School absences and alcohol consumption") 

g3 <- ggplot(alc, aes(x = high_use, y = goout, col = high_use))

p3=g3 + geom_boxplot() + xlab("Alcohol Consumption")+ ylab("Going Out With Friends")  + ggtitle("Going out with friends and alcohol consumption") 
g4 <- ggplot(alc, aes(x = high_use, y = famrel, col = high_use))

p4=g4 + geom_boxplot() + xlab("Alcohol Consumption")+ ylab("Quality Family Relationship")  + ggtitle("Family relationship and alcohol consumption") 

ggarrange(p1, p2, p3 , p4,  labels = c("A", "B", "C", "D"), ncol = 2, nrow = 2)

```
The four box plots above show how four of the chosen variables are associated with alcohol consumption. In each of the plots, x-axis shows the two different factors that measure the level of alcohol consumption i.e True for high consumption and False for low consumption and y-axis shows measurements for dependent variables i.e the four variables I have chosen. All of the box plots above show that what I hypothesized about the variables I selected in terms of alcohol consumption seem to be valid. We can see, they are valid but are these significantly valid observations? I will do a series of modeling and validations in the following sections.


**Logistic Regression**  

Now we will do logistic regression where alcohol consumption (high_use) is target variable and four variables (studytime, goout, absences, famrel) I selected are the predictors.
```{r}
m<-glm(high_use ~ studytime + goout + absences + famrel, data = alc, family = "binomial")
summary(m)
```


Among four variables, going out with friends (goout) is strongly coorelated (Pr = 2.82e-10) with alcohol consumption whereas quality of the family relationship (famrel) has comparatively lower impact towards alcohol consumption. Moreover, all four variables are significantly associated with alcohol consumption. Out of four variables, weekly study time (studytime) and the quality of family relationship (famrel) are inversely related to alcohol consumption. In other words, the more the number of hours spent in studying and the better the quality of the samily relationship, the lower the alcohol consumption. On the other hand, the number of school absences and frequency of going out with friends is positively correlated with alcohol consumption. This means that, if a student has higher number of school absences and goes out frequently with friends, his alcohol consumption is higher. 

I will further delve into my model by evaluating it in terms of coefficients, odds ratio and confidence intervals. 
```{r}
Coef<-coef(m)
OR<-Coef %>% exp
CI<-confint(m) %>% exp
cbind(Coef, OR, CI)

```
In general, If odds ratio is greater than 1, increase in explanotary variable will increase the response probability p whereas if odds ratio is less than 1, then increase in explanatory varialbe will decrease the response probability p. And if odds ratio equals to 1 then there is no effect of explanatory variable on response variable. According to these statements on odds ratios, the frequency of going out and the number of school absences have positive association with high alcohol usage. On the other hand, study time  and family relationship seem to be negatively associated with high alcohol usage, because their odds ratio are smaller than one. With regards to confidence interval, the odds ratio for going out (goout) has the widest confidence interval i.e 2.73 (97.5%) and the study time has the narrowest confidence interval of 0.79 (97.5%). As none of the odds ratio have confidence interval of 1, we can claim that all of the explanatory variables have effect on the odds of outcome i.e. high alcohol usage.  


 **Exploring predictive power of the model**  
 
 To get insight into the predictive power of my model, I will compare model's prediction with the probability of actual vaules. 
 
```{r}
 #predict the probability
 
 pred_prob <- predict(m, type = "response")
 
 #add predicted probabilities and mutate the model
 alc<-mutate(alc, probability = pred_prob)
 #we will use the probability to validate the probabilities of choses four variables
 alc<-mutate(alc, prediction = probability > 0.5)
 table(high_use = alc$high_use, prediction = alc$prediction)
 
```
Based on the 2x2 cross-tabulation, we can see that my model predicted 65 false positives and 26 true negatives. In other words, prediction for a total of (65+26) 91 students is not true. To be more precise, we can check the overall percentage that the model is giving wrong prediction. 
```{r}
#first we need to define loss function
LF<-function(class, prob){
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}
#now we compute the average number of wrong predictions
LF(alc$high_use, alc$prob)
```
Now we can say that up to 24% of the predictions made by my model are false.   

**Cross Validation**  

Here we will perform 10-fold cross validation of our model

```{r}
#load required library
library(boot)

CV<-cv.glm(data = alc, cost = LF, glmfit = m, K = 10 )
#finally look at the average number of wrong predictions
CV$delta[1]
```
Now, after performing 10-fold cross validation, the perfomance of my model slightly increased. And yes, I can proudly claim that my model has better test set performance (24%) than the one we practised in data camp exercise(26%).

