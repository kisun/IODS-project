#Dimensionality Reduction Techniques

In this chapter, we will practice dimensionality reduction techniques using "human" data which was originated from the United Nations Development Programme (UNDP). Additional information about the data can be found [here](http://hdr.undp.org/en/content/human-development-index-hdi).

## RStudio Exercise 5  

**Data Exploration**  

First we will load the data into R and get an overview of it.
```{r, ex1}
human<-read.table("data/human.csv")
#head(human)
dim(human)
str(human)
colnames(human)
```
The subset of the data used in this exercise contain eight variables and 155 observations. Out of the eight variables, **GNI** and **Mat.Mor** are integer variables and the rest of the six variables are all numerical. In the following table, you may see what kind of information all these variables are telling or storing in the data frame.

Variables | Description
-----------|---------------------------------------------------------------------------
Edu2.FM | ratio of females and males with at least secondary education
Labo.FM | ratio of females and males in labour force
Edu.Exp | expected years of schooling
Life.Exp | life expectancy at birth
GNI | gross national income per capita
Mat.Mor | maternal mortality ratio
Ado.Birth | adolescent birth rate
Parli.F| percentage of female representatives in parliament

**Data Summary**  
As in earlier exercises, we will proceed with data summary. Let's first take a look at the summary of the data.
``` {r, ex2.1}
library(pander)
pandoc.table(summary(human), caption = "Summary of Human data", split.table = 80)
```

```{r, fig.width=10, fig.height=10, ex2.2}
library(GGally)
library(ggplot2)
ggpairs(human, mapping = aes(alpha = 0.3), lower = list(combo = wrap("facethist")))


```

Data summary shows some interesting observations for the variables. For instance, adoloscent birth rate (Ado.Birth) is positively correlated (0.759) with maternal mortality ratio but negatively correlated (-0.857) with life expectancy at birth (Life.Exp). Similarly, ratio of females and males with secondary education (Edu2.FM) and expected years of schooling (Edu.Exp) are both positively correlated with life expectancy at birth (Life.Exp). On the other hand, there is very little correlation between the ratio of females and males in labour force (Labo.FM) with *Edu.Exp* and *GNI*. 

**Principal Component Analysis**  

In the following section, we will summarize the principal components and make a principal component analysis (PCA) plot. Firse, PCA is done on non-standardized data followed up by standardized data.
```{r, ex3, fig.height=11, fig.width=11}
pca_human<-prcomp(human)
sum_pca_human<-summary(pca_human)
sum_pca_human
sum_pca_human_var<-sum_pca_human$sdev^2
sum_pca_human_var
pca_pr <- round(100*sum_pca_human$importance[2, ], digits = 1)
pc_lab<-paste0(names(pca_pr), " (", pca_pr, "%)")

biplot(pca_human, cex = c(0.8, 1), col = c("grey40", "deeppink2"), xlab = pc_lab[1], ylab = pc_lab[2], main = "PCA plot of non-scaled human data")

#biplot(pca_human, choices = 1:2, cex = c(1, 1), col = c("grey40", "deeppink2"),sub = "PC1 & PC2 with non-standardised dataset")

```
The PCA biplot above does not provide meaningful interpration to the data as it shows that single variable *GNI* has dominant impact and greater weight. Moreover, *GNI* has larger variance compared to other variables.

**Data Standardization**  

Next, we will scale the variables in the human data and compute principal components and plot the results.
```{r, ex4, fig.height=10, fig.width=10}

pca_human_s<-prcomp(human, scale. = TRUE)
sum_pca_human_s<-summary(pca_human_s)
pca_pr_s <- round(100*sum_pca_human_s$importance[2, ], digits = 1)
pc_lab<-paste0(names(pca_pr_s), " (", pca_pr_s, "%)")

sum_pca_human_var_s<-sum_pca_human_s$sdev^2
sum_pca_human_var_s

biplot(pca_human_s, cex = c(0.8, 1), col = c("grey40", "deeppink2"), xlab = pc_lab[1], ylab = pc_lab[2], main = "PCA plot of scaled human data")

```
Here, after standardization, we can see that the plots look different and thus the results are different. The results are different after scaling because PCA is more sensitive and informative when the original features are scaled. Moreover, PCA assumes that features with lareger variance are more important that those with smaller variance. In non-scaled pca plot, we observed that the variable with higher values have bigger influence as is the case in *GNI* variable. After scaling the data, the variance between the variables is more reasonable. The first principal component (PC1) explains 53% of the variation compared to 100% when the data was not scaled.
**Personal Interpretation on Biplot**  

My personal interpretation of the first two principal component dimensions based on the biplot drawn after PCA on the standardized human data is as follows:  

1. Correlation between variables: Smaller angle between the arrows explains greater correlation between the variables. With this assumption in mind, we can see that four variables, namely *Edu.Exp*, *Life.Exp*, *GNU* and *EDU.FM* are correlated out of which *GNU* and *EDU2.FM* have the highest correlation as explained by the arrows and the angles formed by those arrows. Similarly, *Parli.F* and *Labo.FM* are also correlated and so are the variables *Mat.Mor* and *Ado.Birth*. Furthermore, the plot also shows that *Life.Exp* and *Ado.Birth* are least correlated as they are farthest in the plot (notice the large angle between these two variables).   

2. Correlation between variables and Principal components: Here, the assumption is that the smaller the angle between the variables and principal components, the more positively correlated the variable is. According to this assumption, *Parli.F* and *Labo.FM* are positively correlated to PC1 (i.e they are contributing the direction of PC1) whereas other variables are positively correlated to PC2 and thus directing the arrows towards PC2. In addition, for PC2, *Life.Exp*, *Edu2.FM*, *GNU* and *Ado.FM* have comparatively higher weight than others.

**Multiple Correspondence Analysis**  

We will use tea data from FactoMineR package to practice multiple correspondence analysis (MCA). In this data, there are 300 observations and 36 variables.
```{r, ex5}
library(FactoMineR)
data("tea")
str(tea)
dim(tea)
summary(tea)
```
more 

```{r, ex5.1, fig.width=10, fig.height=15}
library(tidyr)
library(dplyr)
keep<- c("breakfast","tea.time","friends","frequency","Tea","sugar","sex","sophisticated")
my_tea <- dplyr::select(tea, one_of(keep))
gather(my_tea) %>% ggplot(aes(value)) + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) + facet_wrap("key", scales = "free")
```
```{r, ex5.2, fig.width=10, fig.height=10}
mca_tea <- MCA(my_tea, graph=FALSE)
summary(mca_tea, nbelements=Inf, nbind=5)
```

```{r, ex5.3, fig.width=10, fig.height=10}
plot(mca_tea, invisible = c("ind"), habillage = "quali", sub = "MCA of tea dataset")

```
In general, the MCA plot grouped the categories that are mutually similar together and vice versa. Categories such as **tea time**, **friends** are grouped together and such are the categories such as **Not friends** and **Not.tea time**. In other words, friends tend to have tea time together and those do not have tea during other times (i.e not tea times) are not close friends. Also, the plot shows that Females are more social than their male counter parts because they have friends, and participate during the tea time. It also showed that females do not put sugar whereas males put sugar in tea.
 




